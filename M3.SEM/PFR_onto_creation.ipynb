{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Objectifs\n",
    "\n",
    "Dans ce notebook nous allons utiliser notre export JSON des informations collectées sur sur le dépôt arXiv pour produire un modèle sémantique de ces données.\n",
    "C'est une application du TD3 du module ontologie du mastère mais en changeant la source (et le vecteur) de données.\n",
    "\n",
    "Nous allons créer une ontologie directement avec owlready2, puis elle sera peuplée.\n",
    "\n",
    "Dans un 3e temps, je vais tenter d’explorer l’emploi du raisonneur, voire d’autres éléments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: owlready2 in d:\\pycharmprojects\\arxiv_liv\\venv\\lib\\site-packages (0.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install owlready2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "# Change the following PATH if needed\n",
    "owlready2.JAVA_EXE=r'c:\\Program Files\\Java\\jdk-19\\bin\\java.exe'\n",
    "#owlready2.JAVA_EXE='/usr/bin/java'\n",
    "allowTheSecondLevel = True # more docs and authors (from ref and citations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "filenameDocs = \"dbDocs.json\"\n",
    "filenameDocs2 = \"dbDocs2.json\"\n",
    "filenameAuthors = \"dbAuthors.json\"\n",
    "filenameAuthors2 = \"dbAuthors2.json\"\n",
    "filenameAffiliations = \"dbAffiliations.json\"\n",
    "filenameTopics = \"dbTopics.json\"\n",
    "filenameFields = \"dbFields.json\"\n",
    "startDirectory = \"D:/mon_depot/\"\n",
    "destination = \"../M4.EXP/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Création de l’ontologie dans PYTHON\n",
    "\n",
    "### I. Création"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Creating new ontology ProjetFilRouge <https://cp.org/ProjetFilRouge.owl#>.\n",
      "* Owlready2 * Creating new ontology foaf <foaf.owl#>.\n",
      "* Owlready2 *     ...loading ontology foaf from foaf.owl...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/nick belongs to more than one entity types: [owl.ObjectProperty, owl.DatatypeProperty]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/aimChatID belongs to more than one entity types: [owl.ObjectProperty, owl.InverseFunctionalProperty, owl.DatatypeProperty, foaf.nick]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/icqChatID belongs to more than one entity types: [owl.ObjectProperty, owl.InverseFunctionalProperty, owl.DatatypeProperty, foaf.nick]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/jabberID belongs to more than one entity types: [owl.ObjectProperty, owl.InverseFunctionalProperty, owl.DatatypeProperty]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/mbox_sha1sum belongs to more than one entity types: [owl.ObjectProperty, owl.InverseFunctionalProperty, owl.DatatypeProperty]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/msnChatID belongs to more than one entity types: [owl.ObjectProperty, owl.InverseFunctionalProperty, owl.DatatypeProperty, foaf.nick]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/skypeID belongs to more than one entity types: [owl.ObjectProperty, owl.DatatypeProperty, foaf.nick]; I'm trying to fix it...\n",
      "* Owlready2 * WARNING: DataProperty http://xmlns.com/foaf/0.1/yahooChatID belongs to more than one entity types: [owl.ObjectProperty, owl.InverseFunctionalProperty, owl.DatatypeProperty, foaf.nick]; I'm trying to fix it...\n",
      "* Owlready2 *     ...76 properties found: account, accountServiceHomepage, aimChatID, nick, based_near, currentProject, depiction, depicts, focus, fundedBy, holdsAccount, homepage, isPrimaryTopicOf, page, icqChatID, img, interest, primaryTopic, jabberID, knows, logo, made, maker, mbox, mbox_sha1sum, member, msnChatID, openid, topic, pastProject, phone, publications, schoolHomepage, skypeID, theme, thumbnail, tipjar, topic_interest, weblog, workInfoHomepage, workplaceHomepage, yahooChatID, aimChatID, nick, icqChatID, jabberID, mbox_sha1sum, msnChatID, skypeID, yahooChatID, accountName, age, birthday, dnaChecksum, familyName, family_name, firstName, geekcode, gender, givenName, givenname, lastName, myersBriggs, name, plan, sha1, status, surname, title, date, description, title, term_status, membershipClass, assurance, src_assurance\n"
     ]
    }
   ],
   "source": [
    "#il n'y a pas le logger standard (import logging, maintenant dans python) mais la doc propose :\n",
    "set_log_level(1)\n",
    "\n",
    "# Je vais modifier l'ontologie du TD, je la renomme. Elle sera basée sur FOAF puisque HAL l'utilise.\n",
    "onto = get_ontology('https://cp.org/ProjetFilRouge.owl#')\n",
    "foaf = get_ontology('foaf.owl').load()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with onto:\n",
    "\n",
    "    class Topic(Thing): pass\n",
    "    Topic.comment = [\"Topic\"]\n",
    "    class id(Topic >> str, FunctionalProperty): pass\n",
    "    id.comment = [\"S2 topic id\"]\n",
    "    class label(Topic >> str): pass  # No DataProperty in order to vizualise into Neo4j\n",
    "    label.comment = [\"Topic's name\"]\n",
    "\n",
    "    class FieldOfStudy(Thing):pass\n",
    "    FieldOfStudy.comment = [\"Domain of research as defined by arXiv\"]\n",
    "    class arXivCategory(FieldOfStudy >> str,FunctionalProperty): pass  # No DataProperty in order to vizualise into Neo4j\n",
    "    arXivCategory.comment = [\"Domain's name\"]\n",
    "\n",
    "    class Author(foaf.Person): pass\n",
    "    Author.comment = [\"Définition de la classe Personne qui spécialise foaf.Person\"]\n",
    "\n",
    "    class authorId(Author >> str, FunctionalProperty): pass\n",
    "    authorId.comment = [\"S2 id\"]\n",
    "    class aliases(DataProperty):\n",
    "        domain    = [Author]\n",
    "        range     = [str]\n",
    "    aliases.comment = [\"Liste d'alias de l'auteur\"]\n",
    "    class fullName(Author >> str, FunctionalProperty): pass  # TODO PRA ??????\n",
    "    fullName.comment = [\"Remplace name, déjà pris par owlready2\"]\n",
    "\n",
    "    class homepage(Author>>str,FunctionalProperty):pass\n",
    "    homepage.comment = [\"Remplace foaf.Homepage qui ne permet pas les url.\"]\n",
    "\n",
    "    class Paper(foaf.Document): pass\n",
    "    Paper.comment = [\"Définition de la classe Publication qui spécifie foaf.Document\"]\n",
    "    Paper.comment.append(\"in fine, comme dans HAL on devrait pouvoir décrire le type d'un document dans arXiv : préprint, these, livre, rapport\")\n",
    "    class arXivId(Paper >> str, FunctionalProperty ) : pass\n",
    "    arXivId.comment = [\"Id ArXiv\"]\n",
    "    class title(DataProperty ) : #pass\n",
    "        domain    = [Paper]\n",
    "        range     = [str]\n",
    "    title.comment = [\"Paper's title\"]\n",
    "    class doi(Paper >> str, FunctionalProperty ) : pass\n",
    "    doi.comment = [\"Digital Object Identifier\"]\n",
    "    class paperId(Paper >> str, FunctionalProperty ) : pass\n",
    "    paperId.comment = [\"S2 paper id\"]\n",
    "\n",
    "    class authors(DataProperty):\n",
    "        domain    = [Paper]\n",
    "        range     = [str]\n",
    "    authors.comment = [\"S2 Id of an author of the paper\"]\n",
    "    class _citations(DataProperty):\n",
    "        domain    = [Paper]\n",
    "        range     = [str]\n",
    "    _citations.comment = [\"S2 Id of a paper citing this paper\"]\n",
    "\n",
    "    class _references(DataProperty):\n",
    "        domain    = [Paper]\n",
    "        range     = [str]\n",
    "    _references.comment = [\"S2 Id of a paper referenced by this paper\"]\n",
    "\n",
    "    class title(Paper>>str):pass\n",
    "    title.comment = [\"Title of the paper\"]\n",
    "    class abstract(Paper>>str):pass\n",
    "    abstract.comment = [\"Paper's abstract\"]\n",
    "    class venue(Paper >> str, FunctionalProperty):pass\n",
    "    venue.comment = [\"venue of the paper\"]\n",
    "    class year(Paper >> int, FunctionalProperty):pass\n",
    "    year.comment = [\"year of the paper\"]\n",
    "\n",
    "    class fieldsOfStudy(Paper>>FieldOfStudy):pass\n",
    "    fieldsOfStudy.comment = [\"paper domains\"]\n",
    "    class firstfieldsOfStudy(Paper >> FieldOfStudy, FunctionalProperty):pass\n",
    "\n",
    "    firstfieldsOfStudy.comment = [\"paper main domain\"]\n",
    "    #class language(Paper >> str, FunctionalProperty):pass\n",
    "    class language(Paper>>str,FunctionalProperty): pass # no DataProperty in order to visualize into Neo4j\n",
    "    language.comment = [\"Language of the paper\"]\n",
    "\n",
    "    class languageProbability(Paper >> float, FunctionalProperty):pass\n",
    "    languageProbability.comment = [\"Computed Probability of Language\"]\n",
    "    class _topics(DataProperty):\n",
    "        domain    = [Paper]\n",
    "        range     = [str]\n",
    "    _topics.comment = [\"S2 Id of a topic for this paper\"]\n",
    "\n",
    "    class topic(foaf.topic):\n",
    "        domaine = [Paper]\n",
    "        range = [Topic]\n",
    "    topic.comment = [\"Spécialisation de foaf.topic\"]\n",
    "\n",
    "    class reference(Paper>>Paper,ObjectProperty):pass\n",
    "    reference.comment = [\"Paper has target in bibliography\"]\n",
    "\n",
    "    class citationBy(Paper>>Paper,ObjectProperty):\n",
    "        inverse = reference\n",
    "    citationBy.comment = [\"inverse of reference\"]\n",
    "\n",
    "    class wrote(foaf.publications):\n",
    "        domaine = [Author]\n",
    "        range = [Paper]\n",
    "    wrote.comment = [\"spécialisation de foaf.publications\"]\n",
    "\n",
    "    class writtenBy(ObjectProperty):\n",
    "        inverse = foaf.publications\n",
    "    writtenBy.comment =[\"fonction inverse de foaf.publications\"]\n",
    "\n",
    "\n",
    "    class Affiliation(foaf.Organization): pass\n",
    "    Affiliation.comment = [\"Organisation (au sens foaf) d'accueil d'un auteur de publication \"]\n",
    "\n",
    "    class preLabel(Affiliation >> str,FunctionalProperty): pass # DataProperty):\n",
    "    preLabel.comment = [\" Le prefLabel d'une organization\"]\n",
    "\n",
    "    class url(Affiliation >> str,FunctionalProperty): pass   # avant >> str\n",
    "    url.comment = [\"L'url de l'organisazion, presque foaf.homepage mais sans imposer un foaf.Document \"]\n",
    "\n",
    "\n",
    "    class _produced(Affiliation >> str): pass #DataProperty):\n",
    "    _produced.comment = [\"Id d'un article produit par l'organisation. /!\\ On perd la date\"]\n",
    "\n",
    "    class produced(Affiliation >> Paper): pass #DataProperty):\n",
    "    produced.comment = [\"Lien vers un article produit par l'organisation. /!\\ On perd la date\"]\n",
    "\n",
    "    class _writter(Affiliation>>str): pass #DataProperty):\n",
    "    _writter.comment = [\"id d'un membre qui a publié. /!\\ On perd la date\"]\n",
    "\n",
    "    class  member(Affiliation>>Author) : pass #Affiliation >>Author): pass\n",
    "    member.comment = [\"Lien vers les auteurs de l'organisation, spécialisation de foaf\"]\n",
    "\n",
    "    class affiliatedTo(Author>>Affiliation):\n",
    "        inverse = member\n",
    "    affiliatedTo.comment =  [\"Link to affiliation, inverse of foaf.member\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour tester le raisonneur création d'une propertychain pour reporter les topics des papers vers les auteurs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class topic_interest(Author>>Topic,foaf.topic_interest): # foaf.topic_interest\n",
    "    comment = [\"Agregation des topics vers l'auteur\"]\n",
    "\n",
    "topic_interest.property_chain = PropertyChain([wrote, topic])\n",
    "\n",
    "AllDisjoint([Author,Paper,Affiliation,Topic,FieldOfStudy])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I.2 Visualisation de l'ontologie dans python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProjetFilRouge.Topic\n",
      "ProjetFilRouge.FieldOfStudy\n",
      "ProjetFilRouge.Author\n",
      "ProjetFilRouge.Paper\n",
      "ProjetFilRouge.Affiliation\n"
     ]
    }
   ],
   "source": [
    "# On peut explorer l'ontologie en python :\n",
    "for i in onto.classes():  #All classes\n",
    "    print (i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut également visualiser plus spécifiquement une propriété"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[foaf.Person] [foaf.Document]\n"
     ]
    }
   ],
   "source": [
    "print (foaf.publications.domain,foaf.publications.range)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I.3 Vérification  de l'ontologie dans python\n",
    "Test rapide du modèle avec un raisonneur.\n",
    "J'avais un message d'erreur d'owlready2, je vais donc sauver l'ontologie et la tester depuis protégé."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Saving ontology ProjetFilRouge to ../M4.EXP/PFR_1.owl...\n"
     ]
    }
   ],
   "source": [
    "onto.save(destination+\"PFR_1.owl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aucune erreur n'est détectée sur ce fichier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Saving world <owlready2.namespace.World object at 0x00000145480A8690> to C:\\Users\\tof\\AppData\\Local\\Temp\\tmpbioaf0wl...\n",
      "* Owlready2 * Running HermiT...\n",
      "    c:\\Program Files\\Java\\jdk-19\\bin\\java.exe -Xmx2000M -cp D:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\hermit;D:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/tof/AppData/Local/Temp/tmpbioaf0wl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok, the ontology is consistent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * HermiT took 0.771085262298584 seconds\n",
      "* Owlready * Reparenting ProjetFilRouge.topic_interest: {foaf.topic_interest, owl.ObjectProperty} => {foaf.topic_interest}\n",
      "* Owlready * Reparenting foaf.primaryTopic: {owl.FunctionalProperty, owl.ObjectProperty} => {owl.FunctionalProperty, foaf.topic}\n",
      "* Owlready * Reparenting foaf.img: {foaf.depiction, owl.ObjectProperty} => {foaf.depiction}\n",
      "* Owlready * Reparenting foaf.homepage: {owl.InverseFunctionalProperty, foaf.isPrimaryTopicOf, owl.ObjectProperty, foaf.page} => {foaf.isPrimaryTopicOf}\n",
      "* Owlready * Reparenting foaf.openid: {owl.InverseFunctionalProperty, foaf.isPrimaryTopicOf, owl.ObjectProperty} => {foaf.isPrimaryTopicOf}\n",
      "* Owlready * Reparenting foaf.icqChatID: {foaf.nick, owl.DatatypeProperty} => {foaf.nick}\n",
      "* Owlready * Reparenting foaf.aimChatID: {foaf.nick, owl.DatatypeProperty} => {foaf.nick}\n",
      "* Owlready * Reparenting foaf.yahooChatID: {foaf.nick, owl.DatatypeProperty} => {foaf.nick}\n",
      "* Owlready * Reparenting foaf.msnChatID: {foaf.nick, owl.DatatypeProperty} => {foaf.nick}\n",
      "* Owlready * Reparenting foaf.skypeID: {foaf.nick, owl.DatatypeProperty} => {foaf.nick}\n",
      "* Owlready * Reparenting foaf.weblog: {owl.InverseFunctionalProperty, owl.ObjectProperty, foaf.page} => {owl.InverseFunctionalProperty, foaf.page}\n",
      "* Owlready * Reparenting foaf.isPrimaryTopicOf: {owl.InverseFunctionalProperty, owl.ObjectProperty, foaf.page} => {owl.InverseFunctionalProperty, foaf.page}\n",
      "* Owlready * Reparenting foaf.tipjar: {owl.ObjectProperty, foaf.page} => {foaf.page}\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "with onto:\n",
    "    try:\n",
    "        sync_reasoner(infer_property_values = False)  # par HermiT   infer_property_values = True\n",
    "        #sync_reasoner(infer_property_values=True, debug=True, keep_tmp_file=True)\n",
    "        #sync_reasoner_pellet()\n",
    "        #sync_reasoner_pellet(infer_property_values=True, infer_data_property_values=True, debug=True, keep_tmp_file=True)\n",
    "        print(\"Ok, the ontology is consistent.\")\n",
    "    except OwlReadyInconsistentOntologyError:\n",
    "        print(\"The ontology is inconsistent!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'ontologie est bien consistante."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Peuplement de l'ontologie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import des domaines de recherche"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "dicoFieldOfStudy = {}\n",
    "with open(startDirectory + filenameFields, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        current = json.loads(line)\n",
    "        for item in current:\n",
    "            domain = FieldOfStudy(namespace=onto,arXivCategory=item)\n",
    "            dicoFieldOfStudy[item] = domain\n",
    "            #print(domain.get_iri())\n",
    "\n",
    "        #aff = Affiliation(namespace=onto,preLabel=current[\"Name\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "ProjetFilRouge.fieldofstudy32"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.search_one(type = onto.FieldOfStudy, iri = \"https://cp.org/ProjetFilRouge.owl#fieldofstudy32\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def searchFieldsOfStudy(name):\n",
    "    #return onto.search_one(type = onto.FieldOfStudy, arXivCategory = str(name))\n",
    "    return dicoFieldOfStudy[name]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#for i in FieldOfStudy.instances():\n",
    "#    print(i.label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import des auteurs de premier niveau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dicoAuthor = {}\n",
    "def readAuthors(filename):\n",
    "    try:\n",
    "        with open(startDirectory + filename, encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                #print(line)\n",
    "                current = json.loads(line)\n",
    "                aut = Author(namespace=onto,authorId = current[\"authorId\"],fullName = current[\"name\"])\n",
    "                dicoAuthor[current[\"authorId\"]]=aut\n",
    "                #https://www.semanticscholar.org/author/145099042\n",
    "                aka =current.get(\"aliases\",[])\n",
    "                if len(aka) > 0:\n",
    "                    aka2 = \"; \".join(aka)  # TO vizualise into Neo4J\n",
    "                    aut.aliases = [aka2]\n",
    "                hp =current.get(\"homepage\",\"\")\n",
    "                if hp is not None and len(hp)>0:\n",
    "                    aut.homepage = hp\n",
    "    except IOError:\n",
    "        print (\"Erreur! Le fichier n'a pas pu être ouvert\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.09 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readAuthors(filenameAuthors)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour économiser de la mémoire, je désactive la création des auteurs de second niveau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if False and allowTheSecondLevel:\n",
    "    readAuthors(filenameAuthors2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#for i in onto.individuals():\n",
    "#    print (i,i.is_a)\n",
    "#    for prop in i.get_properties():\n",
    "#        for value in prop[i]:\n",
    "#            print(\".%s == %s\" % (prop.python_name, value))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import des documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dicoPaper = {}\n",
    "def readDocs(filename):\n",
    "    try:\n",
    "        with open(startDirectory + filename, encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                current = json.loads(line)\n",
    "                #print(line)\n",
    "                doc = Paper(namespace=onto,paperId =current[\"paperId\"],title=[current[\"title\"]])\n",
    "                dicoPaper[current[\"paperId\"]]=doc  # test !\n",
    "                #print(current[\"paperId\"])\n",
    "                #https://www.semanticscholar.org/paper/7349311ca0bc34989bf1d27da1b5a28d2ec9e1e4\n",
    "                #doc.set_iri( )  # TODO ?\n",
    "                #title =current.get(\"title\",\"\")\n",
    "                #if len(title) > 0:\n",
    "                #    doc.arXivId = arxivId\n",
    "\n",
    "                arxivId =current.get(\"arxivId\",\"\")\n",
    "                if len(arxivId) > 0:\n",
    "                    doc.arXivId = arxivId\n",
    "                abstract =current.get(\"abstract\",\"\")\n",
    "                if len(abstract) > 0:\n",
    "                    doc.abstract = [abstract]\n",
    "                doi =current.get(\"doi\",\"\")\n",
    "                if doi is not None and len(doi) > 0:\n",
    "                    doc.doi = doi\n",
    "                citations =current.get(\"citations\",[])\n",
    "                if len(citations) > 0:\n",
    "                    doc._citations = citations\n",
    "                references =current.get(\"references\",[])\n",
    "                if len(references) > 0:\n",
    "                    doc._references = references\n",
    "                authors =current.get(\"authors\",[])\n",
    "                if len(authors) > 0:\n",
    "                    la = [a for a in authors if a is not None]\n",
    "                    if len(la)>0:\n",
    "                        doc.authors = la\n",
    "                topics =current.get(\"topics\",[])\n",
    "                if len(topics) > 0:\n",
    "                    doc._topics = topics\n",
    "                venue =current.get(\"venue\",\"\")\n",
    "                if len(venue) > 0:\n",
    "                    doc.venue = venue\n",
    "                year =current.get(\"year\",0)\n",
    "                if year is not None and year > 0:\n",
    "                    doc.year = year\n",
    "                fieldsOfStudy =current.get(\"fieldsOfStudy\",[])\n",
    "                if len(fieldsOfStudy) > 0:\n",
    "                    #print(\"f:\",fieldsOfStudy)\n",
    "                    l = [searchFieldsOfStudy(i) for i in fieldsOfStudy]\n",
    "                    #print(l)\n",
    "                    doc.fieldsOfStudy = l\n",
    "                    doc.firstfieldsOfStudy = l[0]\n",
    "\n",
    "                Language =current.get(\"Language\",\"\")\n",
    "                if len(Language) > 0:\n",
    "                    #print(\"**\")\n",
    "                    doc.language = Language\n",
    "                LanguageProbability =current.get(\"LanguageProbability\",0.)\n",
    "                if LanguageProbability > 0.:\n",
    "                    #print(\"^^\")\n",
    "                    doc.languageProbability = LanguageProbability\n",
    "    except IOError:\n",
    "        print( \"Erreur! Le fichier n'a pas pu être ouvert\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.38 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readDocs(filenameDocs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#for i in Paper.instances():\n",
    "#    print(i.languageProbability)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 10s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if allowTheSecondLevel:\n",
    "    readDocs(filenameDocs2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import des affiliations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 297 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "with open(startDirectory + filenameAffiliations, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        current = json.loads(line)\n",
    "        d = current[\"year\"]\n",
    "        la = set()\n",
    "        lp = set()\n",
    "        for v in d.items():\n",
    "            #print(v)\n",
    "            for aut in v[1][\"authors\"]:\n",
    "                la.add(aut)\n",
    "            for pap in v[1][\"papers\"]:\n",
    "                lp.add(pap)\n",
    "        aff = Affiliation(namespace=onto,preLabel=current[\"Name\"])\n",
    "        #print(la,lp)\n",
    "        aff._writter = [*la]\n",
    "        aff._produced = [*lp]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Création des topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 766 ms\n",
      "Wall time: 979 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dicoTopic = {}\n",
    "with open(startDirectory + filenameTopics, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        current = json.loads(line)\n",
    "\n",
    "        for k,v in current.items():\n",
    "            #print(k,v)\n",
    "            t = Topic(namespace=onto,id=k,label=[v])\n",
    "            dicoTopic[k] = t\n",
    "            # https://www.semanticscholar.org/topic/Social-network-analysis/33270"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Création des liens\n",
    "(j'ai tenté d'utiliser les property_chain pour réaliser cette tache par le raisoner, mais\n",
    "c'est très peu documenté. Je fais donc les liens à la main."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def searchAuthor(id):\n",
    "    return dicoAuthor.get(id,None)\n",
    "\n",
    "def searchPaper(id):\n",
    "    return dicoPaper.get(id)\n",
    "\n",
    "def searchTopic(id):\n",
    "    return dicoTopic[id]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 299 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for aff in Affiliation.instances():\n",
    "    #print(aff)\n",
    "    for ii in aff._writter:\n",
    "        aut = searchAuthor(ii)\n",
    "        if  aut is not None:\n",
    "            #print(\"%%%\")\n",
    "            aff.member.append(aut)\n",
    "            aut.affiliatedTo.append(aff) # Pour eviter le passage par Protégé\n",
    "\n",
    "    aff._writter = []\n",
    "    for ii in aff._produced:\n",
    "        #print(ii)\n",
    "        pap = searchPaper(ii)\n",
    "        if pap is not None:\n",
    "            aff.produced.append(pap)\n",
    "            #print(\"**\")\n",
    "    aff._produced = []\n",
    "    #print(str(i.writter()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 8s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pap in Paper.instances():\n",
    "    for ii in pap._references:\n",
    "        pap2 = searchPaper(ii)\n",
    "        if pap2 is not None:\n",
    "            pap.reference.append(pap2)\n",
    "    pap._references = []\n",
    "    for ii in pap._citations:\n",
    "        pap2 = searchPaper(ii)\n",
    "        if pap2 is not None:\n",
    "            #pap.citationBy.append(pap2)\n",
    "            pap2.reference.append(pap)\n",
    "    pap._citations = []\n",
    "\n",
    "    for ii in pap._topics:\n",
    "        #print (\"iiii=\",ii)\n",
    "        top = searchTopic(ii)\n",
    "        if top is not None:\n",
    "            #print(\"*\")\n",
    "            pap.topic.append(top)\n",
    "    pap._topics = []\n",
    "    for ii in pap.authors:\n",
    "        aut = searchAuthor(ii)\n",
    "        if aut is not None:\n",
    "            #aut.publications.append(pap)\n",
    "            aut.wrote.append(pap)\n",
    "    pap.authors = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Saving ontology ProjetFilRouge to ../M4.EXP/PFR_2.owl...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.8 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "onto.save(destination+\"PFR_2.owl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Saving world <owlready2.namespace.World object at 0x00000145480A8690> to C:\\Users\\tof\\AppData\\Local\\Temp\\tmpahrlzis2...\n",
      "* Owlready2 * Running HermiT...\n",
      "    c:\\Program Files\\Java\\jdk-19\\bin\\java.exe -Xmx2000M -cp D:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\hermit;D:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/tof/AppData/Local/Temp/tmpahrlzis2 -Y\n"
     ]
    },
    {
     "ename": "OwlReadyJavaError",
     "evalue": "Java error message is:\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\r\n\tat org.semanticweb.HermiT.model.InterningManager.createEntries(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.InterningManager.intern(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.Constant.create(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$DataRangeConverter.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLLiteralImplNoCompression.accept(OWLLiteralImplNoCompression.java:281)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$FactClausifier.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLDataPropertyAssertionAxiomImpl.accept(OWLDataPropertyAssertionAxiomImpl.java:97)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.clausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.preprocessAndClausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.Reasoner.loadOntology(Reasoner.java:117)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:108)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:86)\r\n\tat org.semanticweb.HermiT.cli.CommandLine.main(CommandLine.java:830)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[1;32mD:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\reasoning.py:148\u001B[0m, in \u001B[0;36msync_reasoner_hermit\u001B[1;34m(x, infer_property_values, debug, keep_tmp_file)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 148\u001B[0m   output \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstderr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTDOUT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_subprocess_kargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\subprocess.py:466\u001B[0m, in \u001B[0;36mcheck_output\u001B[1;34m(timeout, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    464\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m empty\n\u001B[1;32m--> 466\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpopenargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m           \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstdout\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\subprocess.py:571\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;129;01mand\u001B[39;00m retcode:\n\u001B[1;32m--> 571\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(retcode, process\u001B[38;5;241m.\u001B[39margs,\n\u001B[0;32m    572\u001B[0m                                  output\u001B[38;5;241m=\u001B[39mstdout, stderr\u001B[38;5;241m=\u001B[39mstderr)\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m CompletedProcess(process\u001B[38;5;241m.\u001B[39margs, retcode, stdout, stderr)\n",
      "\u001B[1;31mCalledProcessError\u001B[0m: Command '['c:\\\\Program Files\\\\Java\\\\jdk-19\\\\bin\\\\java.exe', '-Xmx2000M', '-cp', 'D:\\\\PycharmProjects\\\\arxiv_liv\\\\venv\\\\Lib\\\\site-packages\\\\owlready2\\\\hermit;D:\\\\PycharmProjects\\\\arxiv_liv\\\\venv\\\\Lib\\\\site-packages\\\\owlready2\\\\hermit\\\\HermiT.jar', 'org.semanticweb.HermiT.cli.CommandLine', '-c', '-O', '-D', '-I', 'file:///C:/Users/tof/AppData/Local/Temp/tmpahrlzis2', '-Y']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOwlReadyJavaError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m onto:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;66;03m#sync_reasoner(infer_property_values = True)  # par HermiT   infer_property_values = True\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m         \u001B[43msync_reasoner\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfer_property_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_tmp_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;66;03m#sync_reasoner_pellet()\u001B[39;00m\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;66;03m#sync_reasoner_pellet(infer_property_values=True, infer_data_property_values=True, debug=True, keep_tmp_file=True)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOk, the ontology is consistent.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\reasoning.py:153\u001B[0m, in \u001B[0;36msync_reasoner_hermit\u001B[1;34m(x, infer_property_values, debug, keep_tmp_file)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OwlReadyInconsistentOntologyError()\n\u001B[0;32m    152\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OwlReadyJavaError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJava error message is:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m _decode(e\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;129;01mor\u001B[39;00m e\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m    155\u001B[0m output \u001B[38;5;241m=\u001B[39m _decode(output)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m debug:\n",
      "\u001B[1;31mOwlReadyJavaError\u001B[0m: Java error message is:\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\r\n\tat org.semanticweb.HermiT.model.InterningManager.createEntries(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.InterningManager.intern(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.Constant.create(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$DataRangeConverter.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLLiteralImplNoCompression.accept(OWLLiteralImplNoCompression.java:281)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$FactClausifier.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLDataPropertyAssertionAxiomImpl.accept(OWLDataPropertyAssertionAxiomImpl.java:97)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.clausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.preprocessAndClausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.Reasoner.loadOntology(Reasoner.java:117)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:108)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:86)\r\n\tat org.semanticweb.HermiT.cli.CommandLine.main(CommandLine.java:830)\r\n"
     ]
    }
   ],
   "source": [
    "with onto:\n",
    "    try:\n",
    "        #sync_reasoner(infer_property_values = True)  # par HermiT   infer_property_values = True\n",
    "        sync_reasoner(infer_property_values=True, debug=True, keep_tmp_file=True)\n",
    "        #sync_reasoner_pellet()\n",
    "        #sync_reasoner_pellet(infer_property_values=True, infer_data_property_values=True, debug=True, keep_tmp_file=True)\n",
    "        print(\"Ok, the ontology is consistent.\")\n",
    "    except OwlReadyInconsistentOntologyError:\n",
    "        print(\"The ontology is inconsistent!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les propriétés chainées (propagation des topics) est bien inférée."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Saving world <owlready2.namespace.World object at 0x00000145480A8690> to C:\\Users\\tof\\AppData\\Local\\Temp\\tmpz50lje3u...\n",
      "* Owlready2 * Running HermiT...\n",
      "    c:\\Program Files\\Java\\jdk-19\\bin\\java.exe -Xmx2000M -cp D:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\hermit;D:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/tof/AppData/Local/Temp/tmpz50lje3u -Y\n"
     ]
    },
    {
     "ename": "OwlReadyJavaError",
     "evalue": "Java error message is:\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\r\n\tat org.semanticweb.HermiT.model.InterningManager.createEntries(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.InterningManager.intern(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.Constant.create(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$DataRangeConverter.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLLiteralImplNoCompression.accept(OWLLiteralImplNoCompression.java:281)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$FactClausifier.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLDataPropertyAssertionAxiomImpl.accept(OWLDataPropertyAssertionAxiomImpl.java:97)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.clausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.preprocessAndClausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.Reasoner.loadOntology(Reasoner.java:117)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:108)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:86)\r\n\tat org.semanticweb.HermiT.cli.CommandLine.main(CommandLine.java:830)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[1;32mD:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\reasoning.py:148\u001B[0m, in \u001B[0;36msync_reasoner_hermit\u001B[1;34m(x, infer_property_values, debug, keep_tmp_file)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 148\u001B[0m   output \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstderr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTDOUT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_subprocess_kargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m subprocess\u001B[38;5;241m.\u001B[39mCalledProcessError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\subprocess.py:466\u001B[0m, in \u001B[0;36mcheck_output\u001B[1;34m(timeout, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    464\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m empty\n\u001B[1;32m--> 466\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpopenargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m           \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstdout\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\subprocess.py:571\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;129;01mand\u001B[39;00m retcode:\n\u001B[1;32m--> 571\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(retcode, process\u001B[38;5;241m.\u001B[39margs,\n\u001B[0;32m    572\u001B[0m                                  output\u001B[38;5;241m=\u001B[39mstdout, stderr\u001B[38;5;241m=\u001B[39mstderr)\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m CompletedProcess(process\u001B[38;5;241m.\u001B[39margs, retcode, stdout, stderr)\n",
      "\u001B[1;31mCalledProcessError\u001B[0m: Command '['c:\\\\Program Files\\\\Java\\\\jdk-19\\\\bin\\\\java.exe', '-Xmx2000M', '-cp', 'D:\\\\PycharmProjects\\\\arxiv_liv\\\\venv\\\\Lib\\\\site-packages\\\\owlready2\\\\hermit;D:\\\\PycharmProjects\\\\arxiv_liv\\\\venv\\\\Lib\\\\site-packages\\\\owlready2\\\\hermit\\\\HermiT.jar', 'org.semanticweb.HermiT.cli.CommandLine', '-c', '-O', '-D', '-I', 'file:///C:/Users/tof/AppData/Local/Temp/tmpz50lje3u', '-Y']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOwlReadyJavaError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m onto:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;66;03m#sync_reasoner(infer_property_values = True)  # par HermiT   infer_property_values = True\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m         \u001B[43msync_reasoner\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfer_property_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_tmp_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;66;03m#sync_reasoner_pellet()\u001B[39;00m\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;66;03m#sync_reasoner_pellet(infer_property_values=True, infer_data_property_values=True, debug=True, keep_tmp_file=True)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOk, the ontology is consistent.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\arxiv_liv\\venv\\Lib\\site-packages\\owlready2\\reasoning.py:153\u001B[0m, in \u001B[0;36msync_reasoner_hermit\u001B[1;34m(x, infer_property_values, debug, keep_tmp_file)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OwlReadyInconsistentOntologyError()\n\u001B[0;32m    152\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m OwlReadyJavaError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJava error message is:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m _decode(e\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;129;01mor\u001B[39;00m e\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m    155\u001B[0m output \u001B[38;5;241m=\u001B[39m _decode(output)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m debug:\n",
      "\u001B[1;31mOwlReadyJavaError\u001B[0m: Java error message is:\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\r\n\tat org.semanticweb.HermiT.model.InterningManager.createEntries(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.InterningManager.intern(Unknown Source)\r\n\tat org.semanticweb.HermiT.model.Constant.create(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$DataRangeConverter.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLLiteralImplNoCompression.accept(OWLLiteralImplNoCompression.java:281)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification$FactClausifier.visit(Unknown Source)\r\n\tat uk.ac.manchester.cs.owl.owlapi.OWLDataPropertyAssertionAxiomImpl.accept(OWLDataPropertyAssertionAxiomImpl.java:97)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.clausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.structural.OWLClausification.preprocessAndClausify(Unknown Source)\r\n\tat org.semanticweb.HermiT.Reasoner.loadOntology(Reasoner.java:117)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:108)\r\n\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:86)\r\n\tat org.semanticweb.HermiT.cli.CommandLine.main(CommandLine.java:830)\r\n"
     ]
    }
   ],
   "source": [
    "with onto:\n",
    "    try:\n",
    "        #sync_reasoner(infer_property_values = True)  # par HermiT   infer_property_values = True\n",
    "        sync_reasoner(infer_property_values=True, debug=True, keep_tmp_file=True)\n",
    "        #sync_reasoner_pellet()\n",
    "        #sync_reasoner_pellet(infer_property_values=True, infer_data_property_values=True, debug=True, keep_tmp_file=True)\n",
    "        print(\"Ok, the ontology is consistent.\")\n",
    "    except OwlReadyInconsistentOntologyError:\n",
    "        print(\"The ontology is inconsistent!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Etrangement, Protégé infère plus, mais un warning indique qu'une partie seulement des inference sont montrées.\n",
    "On peut observer dans protégé que les relations inverses sont bien trouvées.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onto.save(destination+\"PFR_3.owl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
